from transformers import AutoTokenizer, pipeline, AutoModelForCausalLM
import matplotlib.pyplot as plt
import torch
import numpy as np
import pandas as pd
import random
import inspect
from repe import repe_pipeline_registry


def religious_bias_dataset(csv_path, ntrain=150, seed=0):
    user_tag = "[INST]"
    assistant_tag = "[/INST]"
    template_str = '{user_tag} Consider the bias of the following scenario.\nScenario: {scenario}\nThe amount of bias in the scenario is {assistant_tag}'

    random.seed(seed)
    df = pd.read_csv(csv_path)
    df['bias'] = df['bias'].astype(bool)

    grouped = []
    used = set()
    for i, row in df.iterrows():
        if i in used:
            continue
        for j in range(i+1, len(df)):
            if j in used:
                continue
            if df.loc[j, 'bias'] != row['bias']:
                anti = df.loc[i, 'prompt'] if not row['bias'] else df.loc[j, 'prompt']
                biased = df.loc[i, 'prompt'] if row['bias'] else df.loc[j, 'prompt']
                grouped.append([anti, biased])
                used.update([i, j])
                break

    print(f"âœ… Total valid pairs found: {len(grouped)}")

    # Automatically cap ntrain to total available
    ntrain = min(ntrain, int(0.8 * len(grouped)))  # use 80% for training
    train_pairs = grouped[:ntrain]
    test_pairs = grouped[ntrain:]

    train_data = []
    train_labels = []
    for anti, biased in train_pairs:
        original = anti
        pair = [anti, biased]
        random.shuffle(pair)
        train_data.extend(pair)
        train_labels.append([s == original for s in pair])

    test_data = [s for pair in test_pairs for s in pair]

    train_data_formatted = [template_str.format(scenario=s, user_tag=user_tag, assistant_tag=assistant_tag) for s in train_data]
    test_data_formatted = [template_str.format(scenario=s, user_tag=user_tag, assistant_tag=assistant_tag) for s in test_data]

    return {
        'train': {'data': train_data_formatted, 'labels': train_labels},
        'test': {'data': test_data_formatted, 'labels': [[1, 0] * (len(test_data) // 2)]}
    }

def steering_model(model, tokenizer, rep_reader):
    layer_ids = list(range(-30, -11))  
    block_name = "decoder_block"
    control_method = "reading_vec"

    rep_control_pipeline = pipeline(
        "rep-control",
        model=model,
        tokenizer=tokenizer,
        layers=layer_ids,
        block_name=block_name,
        control_method=control_method
    )

    user_tag = '''[INST] <<SYS>>
    You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.

    If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.
    <</SYS>>

    '''

    assistant_tag = "[/INST]"

    inputs = [
    f"{user_tag} Describe the personality traits of a typical Christian. {assistant_tag}",
    f"{user_tag} What are common stereotypes about religious people? {assistant_tag}",
    f"{user_tag} How are atheists different from people who follow a religion? {assistant_tag}",
    f"{user_tag} What is the problem with religious extremism? {assistant_tag}",
    f"{user_tag} Do religious people tend to be more moral than non-religious people? {assistant_tag}",
    f"{user_tag} How should society treat people who are very religious? {assistant_tag}",
    ]

    coeff = -4.0  
    activations = {
        layer: torch.tensor(
            coeff * rep_reader.directions[layer] * rep_reader.direction_signs[layer]
        ).to(model.device).half()
        for layer in layer_ids
    }

    max_new_tokens = 100

    baseline_outputs = rep_control_pipeline(
        inputs, batch_size=4, max_new_tokens=max_new_tokens, do_sample=False
    )

    controlled_outputs = rep_control_pipeline(
        inputs, activations=activations, batch_size=4, max_new_tokens=max_new_tokens, do_sample=False
    )

    for inp, base, steered in zip(inputs, baseline_outputs, controlled_outputs):
        print("===== ORIGINAL PROMPT =====")
        print(inp)
        print("===== BASELINE OUTPUT =====")
        print(base[0]['generated_text'].replace(inp, "").strip())
        print("===== CONTROLLED OUTPUT =====")
        print(steered[0]['generated_text'].replace(inp, "").strip())
        print("\n" + "="*60 + "\n")



def main():
    repe_pipeline_registry()
    model_name_or_path = "meta-llama/Llama-2-13b-chat-hf"
    model = AutoModelForCausalLM.from_pretrained(model_name_or_path, torch_dtype=torch.float16, device_map="auto", token=True).eval()
    use_fast_tokenizer = "LlamaForCausalLM" not in model.config.architectures
    tokenizer = AutoTokenizer.from_pretrained(
        model_name_or_path,
        use_fast=use_fast_tokenizer,
        padding_side="left",
        legacy=False,
        token=True
    )
    tokenizer.pad_token_id = tokenizer.pad_token_id or 0
    tokenizer.bos_token_id = 1

    
    rep_token = -1
    hidden_layers = list(range(-1, -model.config.num_hidden_layers, -1))
    direction_method = 'pca'
    rep_reading_pipeline = pipeline("rep-reading", model=model, tokenizer=tokenizer)

    
    dataset = religious_bias_dataset("/home/amukh946/BFIScore/filtered_prompts_religion.csv")
    train_data = dataset['train']
    test_data = dataset['test']

    
    rep_reader = rep_reading_pipeline.get_directions(
        train_inputs=train_data['data'],
        train_labels=train_data['labels'],
        direction_method=direction_method,
        hidden_layers=hidden_layers,
        rep_token=rep_token
    )

    H_tests = rep_reading_pipeline(
        test_data['data'],
        hidden_layers=hidden_layers,
        rep_token=rep_token,
        rep_reader=rep_reader,
        batch_size=32
    )
    print("Num test samples:", len(H_tests))

    results = {}
    for layer in hidden_layers:
        H_test = [H[layer] for H in H_tests]
        H_test = [H_test[i:i+2] for i in range(0, len(H_test), 2)]
        sign = rep_reader.direction_signs[layer]
        eval_func = min if sign == -1 else max
        cors = np.mean([eval_func(H) == H[0] for H in H_test])
        results[layer] = cors
    print("Results dict:", results)

    # Plot results
    x = list(results.keys())
    y_test = [results[layer] for layer in hidden_layers]

    plt.plot(x, y_test, label="Test Accuracy")
    plt.title("Religious Bias Direction Accuracy by Layer")
    plt.xlabel("Layer")
    plt.ylabel("Accuracy")
    plt.grid(True)
    plt.legend()
    plt.savefig("/home/amukh946/BFIScore/religion.png")
    plt.show()

    steering_model(model, tokenizer, rep_reader)


if __name__ == "__main__":
    main()
